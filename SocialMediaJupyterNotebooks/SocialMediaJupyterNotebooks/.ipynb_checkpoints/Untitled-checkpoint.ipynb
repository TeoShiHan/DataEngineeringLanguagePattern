{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ace7b9df-9bdd-418d-9c2a-861be534f23a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: hive.metastore.uris\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/pc/TestJupyter/opt/spark-3.3.0/spark-3.3.0-bin-hadoop3/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/pc/.ivy2/cache\n",
      "The jars for the packages stored in: /home/pc/.ivy2/jars\n",
      "org.apache.spark#spark-avro_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-d97da1dc-e448-494b-bccd-446a77c0aac7;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.spark#spark-avro_2.12;3.3.0 in central\n",
      "\tfound org.tukaani#xz;1.8 in central\n",
      "\tfound org.spark-project.spark#unused;1.0.0 in central\n",
      ":: resolution report :: resolve 144ms :: artifacts dl 4ms\n",
      "\t:: modules in use:\n",
      "\torg.apache.spark#spark-avro_2.12;3.3.0 from central in [default]\n",
      "\torg.spark-project.spark#unused;1.0.0 from central in [default]\n",
      "\torg.tukaani#xz;1.8 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-d97da1dc-e448-494b-bccd-446a77c0aac7\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/4ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/03 10:29:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import findspark\n",
    "findspark.init(\"/home/pc/TestJupyter/opt/spark-3.3.0/spark-3.3.0-bin-hadoop3\")\n",
    "import pyspark\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import HiveContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "\n",
    "\n",
    "# warehouse_location points to the default location for managed databases and tables\n",
    "os.environ[\"PYSPARK_PYTHON\"]=\"/home/pc/TestJupyter/opt/spark-3.3.0/venv-spark/bin/python39\"\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-avro_2.12:3.3.0  pyspark-shell'\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL Hive integration example\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", \"hdfs://10.123.51.78:8000/user/hive/warehouse\") \\\n",
    "    .config(\"spark.sql.catalogImplementation\", \"hive\")\\\n",
    "    .config(\"hive.metastore.uris\", \"thrift://g2.bigtop.it:9083\")\\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a857c3e-16cc-47ce-843c-c58988f4a490",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.window import Window\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import row_number\n",
    "from pyspark.sql.functions import desc\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85dfb6f-7f7d-4990-914e-e1550bc3af72",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Overall highest tag ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c1690831-f6e1-476c-a767-99b6d6682c66",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Path does not exist: file:/home/pc/Assignment/SocialMedia/Main/NO_PUNCT_GRAM.avro",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [114]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mavro\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNO_PUNCT_GRAM.avro\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/TestJupyter/opt/spark-3.3.0/spark-3.3.0-bin-hadoop3/python/pyspark/sql/readwriter.py:177\u001b[0m, in \u001b[0;36mDataFrameReader.load\u001b[0;34m(self, path, format, schema, **options)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(path) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n",
      "File \u001b[0;32m~/TestJupyter/opt/spark-3.3.0/spark-3.3.0-bin-hadoop3/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/TestJupyter/opt/spark-3.3.0/spark-3.3.0-bin-hadoop3/python/pyspark/sql/utils.py:196\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    192\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Path does not exist: file:/home/pc/Assignment/SocialMedia/Main/NO_PUNCT_GRAM.avro"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"avro\").load(\"NO_PUNCT_GRAM.avro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "43afd5dd-a2cc-4f49-8f9f-733fd6845458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[row_id: bigint, sentence_id: int, pos: int, token_gram: string, tag_gram: string, lang_gram: string, gram_type: string]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac2858c7-22c2-4ac3-8b5b-4cf591c8d905",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "one = df.rdd.map(lambda x : (x.tag_gram, 1))\n",
    "mapRslt = one.reduceByKey(lambda K1_V1, K1_V2 : K1_V1+K1_V2).toDF([\"tag_gram\",\"frequency\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ae65bfef-cf5e-4215-b840-78255622133e",
   "metadata": {},
   "outputs": [],
   "source": [
    "descDF =                                                                                                                                                                                  \\\n",
    "    mapRslt                                                                                                                                                                            \\\n",
    "        .select(\"tag_gram\",\"frequency\", F.row_number()\n",
    "        .over(Window.partitionBy()\n",
    "                .orderBy(desc(mapRslt['frequency'])))\n",
    "        .alias(\"id\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "741a56de-305a-4edd-898f-4149928c54c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[tag_gram: string, frequency: bigint, id: int]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1279dbfa-833a-4c74-b95c-e173eb7ca89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = descDF.limit(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e6ba09ba-42d1-4f89-8d02-0b6d7bdf8a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/03 07:15:51 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/10/03 07:15:51 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/10/03 07:15:51 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    }
   ],
   "source": [
    "frame = p.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5a13e8b5-9e5f-4794-a314-f222d3d5b342",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_grams = frame[\"tag_gram\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3016cd3a-66ad-48bc-a62e-8be2bce725fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "examples = [', '.join(spark.sql(f\"select token_gram from socialmediangrams where tag_gram = '{pattern}' limit 5\").toPandas()[\"token_gram\"].tolist()) for pattern in tag_grams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4d767946-8d9e-41cc-91f3-7f52964974d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.insert(3, \"eg\",examples, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1e2abfdb-672d-4f45-84c7-8d67c0b47726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag_gram</th>\n",
       "      <th>frequency</th>\n",
       "      <th>id</th>\n",
       "      <th>eg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NOUN NOUN</td>\n",
       "      <td>7552078</td>\n",
       "      <td>1</td>\n",
       "      <td>repeart lg, material kain, bubble wrap, tq sel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NOUN ADJ</td>\n",
       "      <td>4471212</td>\n",
       "      <td>2</td>\n",
       "      <td>keadaan baik, order lmbt, barang berpatutan, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADJ NOUN</td>\n",
       "      <td>3822446</td>\n",
       "      <td>3</td>\n",
       "      <td>cam botol, cam botol, berbaloi treats, berbalo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NOUN ADV</td>\n",
       "      <td>3188510</td>\n",
       "      <td>4</td>\n",
       "      <td>first time, first time, order lagi, first time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADP NOUN</td>\n",
       "      <td>3108214</td>\n",
       "      <td>5</td>\n",
       "      <td>dari seller, dari seller, dari seller, dari se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ADV VERB</td>\n",
       "      <td>2985662</td>\n",
       "      <td>6</td>\n",
       "      <td>time beli, time beli, time beli, time beli, ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VERB NOUN</td>\n",
       "      <td>2941232</td>\n",
       "      <td>7</td>\n",
       "      <td>beli barang, duk shah, repeat order, boleh rep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PROPN PROPN</td>\n",
       "      <td>2939942</td>\n",
       "      <td>8</td>\n",
       "      <td>cotton soo, thank you, recommended seller, kak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PROPN NOUN</td>\n",
       "      <td>2805492</td>\n",
       "      <td>9</td>\n",
       "      <td>alam order, lajuu terima, good job, vietnam ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ADV ADJ</td>\n",
       "      <td>2361346</td>\n",
       "      <td>10</td>\n",
       "      <td>sangat berbaloi, memang okay, memang terbaik, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NOUN VERB</td>\n",
       "      <td>2263388</td>\n",
       "      <td>11</td>\n",
       "      <td>baby boleh, wrap xdak, beza berkotak, bayi ter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>VERB ADP</td>\n",
       "      <td>2045768</td>\n",
       "      <td>12</td>\n",
       "      <td>beli dari, beli dari, beli dari, beli dari, be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NOUN ADP</td>\n",
       "      <td>1961958</td>\n",
       "      <td>13</td>\n",
       "      <td>seluar dalam, barang dari, brang sampai, baran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ADJ ADV</td>\n",
       "      <td>1635044</td>\n",
       "      <td>14</td>\n",
       "      <td>laju lagi, first time, first time, cepat jugak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NOUN PROPN</td>\n",
       "      <td>1615594</td>\n",
       "      <td>15</td>\n",
       "      <td>shah alam, penghantaran lajuu, seller vietnam,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tag_gram  frequency  id  \\\n",
       "0     NOUN NOUN    7552078   1   \n",
       "1      NOUN ADJ    4471212   2   \n",
       "2      ADJ NOUN    3822446   3   \n",
       "3      NOUN ADV    3188510   4   \n",
       "4      ADP NOUN    3108214   5   \n",
       "5      ADV VERB    2985662   6   \n",
       "6     VERB NOUN    2941232   7   \n",
       "7   PROPN PROPN    2939942   8   \n",
       "8    PROPN NOUN    2805492   9   \n",
       "9       ADV ADJ    2361346  10   \n",
       "10    NOUN VERB    2263388  11   \n",
       "11     VERB ADP    2045768  12   \n",
       "12     NOUN ADP    1961958  13   \n",
       "13      ADJ ADV    1635044  14   \n",
       "14   NOUN PROPN    1615594  15   \n",
       "\n",
       "                                                   eg  \n",
       "0   repeart lg, material kain, bubble wrap, tq sel...  \n",
       "1   keadaan baik, order lmbt, barang berpatutan, r...  \n",
       "2   cam botol, cam botol, berbaloi treats, berbalo...  \n",
       "3   first time, first time, order lagi, first time...  \n",
       "4   dari seller, dari seller, dari seller, dari se...  \n",
       "5   time beli, time beli, time beli, time beli, ti...  \n",
       "6   beli barang, duk shah, repeat order, boleh rep...  \n",
       "7   cotton soo, thank you, recommended seller, kak...  \n",
       "8   alam order, lajuu terima, good job, vietnam ba...  \n",
       "9   sangat berbaloi, memang okay, memang terbaik, ...  \n",
       "10  baby boleh, wrap xdak, beza berkotak, bayi ter...  \n",
       "11  beli dari, beli dari, beli dari, beli dari, be...  \n",
       "12  seluar dalam, barang dari, brang sampai, baran...  \n",
       "13  laju lagi, first time, first time, cepat jugak...  \n",
       "14  shah alam, penghantaran lajuu, seller vietnam,...  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0c59027-c624-4dac-994c-648e000c8a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree(\"temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0ef038-aa55-4883-8263-00faf3788332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140850cc-47e4-43b3-ac6b-c203f942b082",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b33d85f-15b8-48a6-b3ce-860280240211",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9447cbe-f077-495e-9581-32d605f9b6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Overall highest frequency token ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "20363e53-1938-424d-9cd7-ef4cccc51520",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\"select token_gram from socialmediangrams\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "510d119f-9ff2-4d73-a326-d47b72ea2692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "one2 = df.rdd.map(lambda x : (x.token_gram, 1))\n",
    "mapRslt2 = one2.reduceByKey(lambda K1_V1, K1_V2 : K1_V1+K1_V2).toDF([\"token_gram\",\"frequency\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0572dbe2-bba3-444d-ae72-7c0448846750",
   "metadata": {},
   "outputs": [],
   "source": [
    "descDF2 =                                                                                                                                                                                  \\\n",
    "    mapRslt2                                                                                                                                                                            \\\n",
    "        .select(\"token_gram\",\"frequency\", F.row_number()\n",
    "        .over(Window.partitionBy()\n",
    "                .orderBy(desc(mapRslt2['frequency'])))\n",
    "        .alias(\"id\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "147209e8-e366-49e9-915b-20fcb326408a",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = descDF2.limit(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "84a95a23-029a-405e-8b8b-a0de66af0142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/03 07:23:53 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/10/03 07:23:53 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/10/03 07:23:53 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "frame = p.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "89c13388-cd94-47b8-9444-82616eafa1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_gram</th>\n",
       "      <th>frequency</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fast delivery</td>\n",
       "      <td>707074</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tq seller</td>\n",
       "      <td>664500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>good condition</td>\n",
       "      <td>652890</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in good</td>\n",
       "      <td>571314</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>terbaik terbaik</td>\n",
       "      <td>462016</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>thank you</td>\n",
       "      <td>451624</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>good product</td>\n",
       "      <td>419842</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>terima kasih</td>\n",
       "      <td>398516</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>received in</td>\n",
       "      <td>394732</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>barang sampai</td>\n",
       "      <td>359026</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>value for</td>\n",
       "      <td>351148</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>for money</td>\n",
       "      <td>347208</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>good value</td>\n",
       "      <td>330122</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>keadaan baik</td>\n",
       "      <td>323002</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>dalam keadaan</td>\n",
       "      <td>320090</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         token_gram  frequency  id\n",
       "0     fast delivery     707074   1\n",
       "1         tq seller     664500   2\n",
       "2    good condition     652890   3\n",
       "3           in good     571314   4\n",
       "4   terbaik terbaik     462016   5\n",
       "5         thank you     451624   6\n",
       "6      good product     419842   7\n",
       "7      terima kasih     398516   8\n",
       "8       received in     394732   9\n",
       "9     barang sampai     359026  10\n",
       "10        value for     351148  11\n",
       "11        for money     347208  12\n",
       "12       good value     330122  13\n",
       "13     keadaan baik     323002  14\n",
       "14    dalam keadaan     320090  15"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae5f4df-d787-4ed2-b02f-8923ad43b340",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-spark",
   "language": "python",
   "name": "venv-spark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
